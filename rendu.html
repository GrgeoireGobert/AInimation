<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>AInimation</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.8.0/css/bulma.min.css">
	<link href="https://fonts.googleapis.com/css?family=Kaushan+Script&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style_article.css">
    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
  </head>
  <body>
  
  
  <section id="article_hero"  class="hero is-medium is-primary" style="background-image: url(banner_script.png);">
  <div class="hero-body">
    <div class="columns">
	<div class="column is-2"></div>
	<div class="column is-8">
      <h1 class="title">
        Rendu
      </h1>
      <h2 class="subtitle">
        A la recherche de la lumi√®re
      </h2>
	</div>
	<div class="column is-2"></div>
    </div>
  </div>
</section>
  
  <div id="burger_menu_full">
	<div id="burger_menu_open" class="burger-menu"><i class="fas fa-bars"></i></div>
	<div id="burger_menu_close" class="burger-menu"><i class="fas fa-times"></i></div>
  </div>
  
  <div id="left_menu" class="left_menu">
	<a id="to_home" href="index.html">AI</a>
	  <nav>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="script.html"><i class="far fa-circle"></i><span class="tooltiptext">Script</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	 
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="storyboard.html"><i class="far fa-circle"></i><span class="tooltiptext">Storyboard</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="modelisation.html"><i class="far fa-circle"></i><span class="tooltiptext">Mod√©lisation</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="texturing.html"><i class="far fa-circle"></i><span class="tooltiptext">Texturing</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="rigging.html"><i class="far fa-circle"></i><span class="tooltiptext">Rigging</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="animation.html"><i class="far fa-circle"></i><span class="tooltiptext">Animation</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="rendu.html"><i class="fas fa-circle"></i><span class="tooltiptext">Rendu</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="son.html"><i class="far fa-circle"></i><span class="tooltiptext">Son</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  </nav>
	 
	<div></div>
	</div>
	
	<div class="columns">
	  <div class="column is-2"></div>
	  <div class="column is-8">
		<section class="section">
			<div class="container">
			  <h1 class="title">Le rendu, qu'est-ce que c'est ?</h1>
				  <h2 class="subtitle">
					<!-- Rien pour l'instant --></br>
				  </h2>
				  
				<p>
				Les √©tapes pr√©c√©dentes ont permis de mod√©liser num√©riquement les diff√©rentes sc√®nes : position et cat√©gorie des sources de lumi√®re, position, orientation et d√©formation des objets, simulation des ph√©nom√®nes physiques, etc. Il est alors temps de synth√©tiser la s√©quence d'images, prises √† un intervalle de temps r√©gulier (au moins 24 images par seconde), pour aboutir √† une s√©quence vid√©o. Cette synth√®se d'image se fait gr√¢ce au <em>Ray Tracing</em> (plus pr√©cis√©ment au <a href="https://fr.wikipedia.org/wiki/Path_tracing"><em>Path Tracing</em></a>) qui consiste √† lancer dans la sc√®ne 3D des rayons partant de la cam√©ra. Ces rayons rebondissent sur les diff√©rents objets et acqui√®rent (lorsqu'ils rencontrent une source d'√©nergie) ou perdent (lorsqu'ils rencontrent un mat√©riau absorbant) de l'√©nergie sur leur trajet. La direction de rebond peut d√©pendre du mat√©riau (par exemple pour un miroir parfait) ou peut √™tre al√©atoire (si le but est d'estimer l'illumination globale en un point). Les informations ainsi r√©colt√©es permettent de synth√©tiser une image r√©aliste, au prix toutefois de nombreuses heures de calcul.
				</p>
				
				<figure class="image" style="width:50%;">
						<img src="images/Rendu_RayTracing_ECL.png" width="100%"></img>
						<p>Exemple de rendu r√©aliste simple r√©alis√© √† l'Ecole Centrale de Lyon, par la m√©thode de <em>Path Tracing</em>. La sph√®re centrale blanche est color√©e par les murs environnants gr√¢ce au calcul d'illumination globale.</p>
				</figure>
				
				<p>
				Comme cela est visible sur l'image pr√©c√©dente, le caract√®re al√©atoire de certains rayons (d√ª √† l'estimation de l'illumination globale par la <a href="https://fr.wikipedia.org/wiki/M%C3%A9thode_de_Monte-Carlo">m√©thode de Monte Carlo</a>) engendre une image bruit√©e. Une des parades √† ce probl√®me est la r√©alisation d'une estimation plus pr√©cise en lan√ßant plus de rayons. Cependant, pour r√©duire la quantit√© de bruit par deux, il est n√©cessaire de multiplier par quatre le nombre de rayons lanc√©s et donc le temps de calcul. Une autre solution consiste √† utiliser l'intelligence artificielle afin de d√©bruiter efficacement l'image obtenue. Cette solution sera pr√©sent√©e par la suite.<br/><br/>
				</p>
				
				<p>
				Pour certaines productions, les choix artistiques ajoutent des contraintes √† l'√©tape de rendu. C'est par exemple le cas du r√©cent film d'animation <em>Spider-Man: New Generation</em> du studio Sony Pictures Animation, qui pr√©entait un aspect "comics" dans ses rendus. L√† encore, l'intelligence artificielle est venue en aide aux artistes afin d'arriver √† leurs fins.<br/>
				Un vaste champ de possibilit√©s artsitiques s'ouvre avec l'arriv√©e r√©cente du transfert de style 3D, permettant ainsi de se lib√©rer de la contrainte de mat√©riaux physiques (voir la page consacr√©e au <a href="texturing.html">texturing</a>) au b√©n√©fice de styles plus exotiques.<br/>
				Ces deux avanc√©es, obtenues gr√¢ce √† l'intelligence artificielle, seront pr√©sent√©es dans les paragraphes suivants.
				</p>
				
				
				  
			</div>
		</section>
		
		
		
		
		
		
		
		
		
		
		
		
		<section class="section">
			<div class="container">
			  <h1 class="title">Le d√©bruitage des rendus</h1>
				  <h2 class="subtitle">
					Corriger les erreurs des estimations de Monte Carlo</br>
				  </h2>
				  
				<p>
				Comme cela a √©t√© expliqu√© en introduction, la synth√®se de rendu par <em>Path Tracing</em> g√©n√®re des r√©sultats physiquement tr√®s justes mais bruit√©s, m√™me en lan√ßant un tr√®s grand nombre de rayons pour le calcul de chaque pixel, √† cause de l'estimation de l'illumination globale par la m√©thode de Monte Carlo. Ce bruit √©tant in√©vitable, une √©tape de filtrage est n√©cessaire afin de r√©duire son impact. La solution classique, visant √† remplacer la valeur d'un pixel de l'image par une moyenne pond√©r√©e des valeurs de ses voisins, pr√©sente un inconv√©nient majeur : comment choisir les pond√©rations adapt√©es alors que la structure du bruit varie d'un endroit √† l'autre de l'image (√† cause de la non-uniformit√© de l'illumination globale) ?<br/>
				Des chercheurs du studio Disney [<a href="#ref_1">1</a>,<a href="#ref_1">2</a>] ont tent√© de r√©soudre ce probl√®me en utilisant des algorithmes d'intelligence artificielle. L'objectif √©tait de mettre au point un r√©seau de neurones convolutionnel capable de pr√©dire le filtre (aussi appel√© "noyau") adapt√© √† chacun des pixels de l'image. Ainsi, l'√©tape de filtrage peut ensuite devenir "dynamique" dans le sens o√π la structure locale du bruit est prise en compte.<br/><br/>		
				</p>
				
				<p>
				L'architecture de la solution consiste en r√©alit√© en deux r√©seaux de neurones convolutionnels : un r√©seau d√©di√© √† la composante diffuse de l'image (part isotrope de la r√©flexion de la lumi√®re) et un autre r√©seau d√©di√© √† la composante sp√©culaire (part anisotrope de la r√©flexion de la lumi√®re). Les √©tapes de la m√©thode sont les suivantes :
				</p>
				<ol>
					<li>S√©paration des donn√©es g√©n√©r√©es par le moteur de rendu : d'un c√¥t√© les informations diffuses, de l'autre les informations sp√©culaires.</li>
					<li>Pr√©-traitement des donn√©es adapt√© √† la cat√©gorie (diffus ou sp√©culaire) : normalisation, passage au logarithme, etc.</li>
					<li>Passage de chacun des pixels (et de son voisinnage) dans les r√©seaux de neurones et application du filtrage.</li>
					<li>Post-traitement des deux images obtenues, visant √† annuler le pr√©-traitement r√©alis√©.</li>
					<li>Fusion des deux composantes (diffuse et sp√©culaire) et obtention de l'image finale d√©bruit√©e.</li>
				</ol>
				
				
				<figure class="image" style="width:90%;">
						<img src="images/Denoising_model_full.png" width="100%"></img>
						<p>Architecture globale de la m√©thode de d√©bruitage par g√©n√©ration de noyaux (<a href="https://studios.disneyresearch.com/2017/07/20/kernel-predicting-convolutional-networks-for-denoising-monte-carlo-renderings/">source</a>)</p>
				</figure>
				
				<p>
				Chacun des deux r√©seaux de neurones convolutionels est compos√©e de 8 couches convolutionneles cach√©es avec 100 filtres 5x5 √† chaque couche. La fonction d'activation ReLu est utilis√©e en sortie de chaque couche. Le r√©seau prend en entr√©e les informations sur un pixel et son voisinage, et il fournit en sortie un noyau de taille 21x21, les pond√©rations √©tant finalement obtenues par normalisation (Softmax). Il suffit ensuite d'appliquer ce filtre au pixel. La fonction de perte choisie est la norme 1 entre le pixel g√©n√©r√© et le pixel cible. L'optimisation se fait de mani√®re classique.
				</p>
				
				<p>
				La jeu d'entrainement est constitu√© de 600 images calcul√©es par <em>Path Tracing</em> avec plusieurs milliers de rayons par pixel (donc des images tr√®s peu bruit√©es) ayant demand√© de nombreuses heures de calcul. Chacune des images est ensuite d√©coup√©e en patchs. Les r√©sultats sont tr√®s bons puisqu'√† partir d'une image synth√©tis√©e avec 32 rayons par pixel, puis d√©bruit√©e en 12 secondes, il est possible d'obtenir un r√©sultat visuellement √©quivalent voire meilleur que la m√™me image synt√©tis√©e avec 128 rayons par pixel ! Les gains de temps sont donc consid√©rables, ce qui explique l'emploi massif de telles m√©thodes de d√©bruitage dans l'industrie du cin√©ma d'animation aujourd'hui.
				</p>
				
				<figure class="image" style="width:100%;">
						<img src="images/Denoising_test_train.png" width="100%"></img>
						<p>(A gauche) Le jeu d'entra√Ænement, compos√© d'images g√©n√©r√©es √† 32 rayons par pixel, et de leur √©quivalent √† 1024 rayons par pixel. (A droite) L'application de l'algorithme de d√©bruitage sur une image √† 32 rayons par pixel : le r√©sultat est visuellement √©quivalent √† une image √† 1024 rayons par pixel (<a href="https://studios.disneyresearch.com/2017/07/20/kernel-predicting-convolutional-networks-for-denoising-monte-carlo-renderings/">source</a>)</p>
				</figure>
				
				  
			</div>
		</section>
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		<section class="section">
			<div class="container">
			  <h1 class="title">Trac√© intelligent de contours</h1>
				  <h2 class="subtitle">
					Le machine learning pour aller aux Oscars</br>
				  </h2>
				  
				  <center>
				  <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Congratulations to the <a href="https://twitter.com/SpiderVerse?ref_src=twsrc%5Etfw">@SpiderVerse</a> cast and crew on their <a href="https://twitter.com/hashtag/Oscars?src=hash&amp;ref_src=twsrc%5Etfw">#Oscars</a> nomination for Best Animated Feature! üï∑Ô∏èüéâ <a href="https://t.co/pstwTwNdHT">pic.twitter.com/pstwTwNdHT</a></p>&mdash; Sony Pictures Animation (@SonyAnimation) <a href="https://twitter.com/SonyAnimation/status/1087712954819108865?ref_src=twsrc%5Etfw">January 22, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
				  </center>
				  
				  
				<p>
				</p>
				  
			</div>
		</section>
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		<section class="section">
			<div class="container">
			  <h1 class="title">Le transfert de style 3D</h1>
				  <h2 class="subtitle">
					Une multitude de possibilit√©s</br>
				  </h2>
				  
				<p>
				</p>
				  
			</div>
		</section>	
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		<section class="section">
			<div class="container refs">
				<h1 class="title">R√©f√©rences</h1>
				<ul>
					<li>[1] : DisneyResearch -
						<a id="ref_1" href="https://studios.disneyresearch.com/2017/07/20/kernel-predicting-convolutional-networks-for-denoising-monte-carlo-renderings/">Kernel-Predicting Convolutional Networks for Denoising Monte Carlo Renderings</a>
					</li>
					<li>[2] : DisneyResearch -
						<a id="ref_2"  href="https://studios.disneyresearch.com/2018/07/30/denoising-with-kernel-prediction-and-asymmetric-loss-functions/">Denoising with Kernel Prediction and Asymmetric Loss Functions</a>
					</li>
					<li>[3] : FXGuide -
						<a id="ref_3"  href="https://www.fxguide.com/fxfeatured/ink-lines-and-machine-learning/?utm_source=twitter&utm_medium=social&utm_campaign=SocialWarfare">Ink Lines and Machine Learning</a>
					</li>
					<li>[4] : D.S√Ωkora et al. -
						<a id="ref_4"  href="https://dcgi.fel.cvut.cz/home/sykorad/styleblit.html">StyleBlit: Fast Example-Based Stylization with Local Guidance</a>
					</li>
				</ul>
			</div>
		</section>
		
	  </div>
	  <div class="column is-2"></div>
	</div>
	
	<footer class="columns">
		<div class="column is-2"></div>
		<div class="column is-8" id="footer_center">
			<div>¬© Gr√©goire GOBERT</div>
			<div>
				<a href="https://twitter.com/gobert_gregoire" style="color:rgb(29,161,242);font-size:1.3em;"><i class="fab fa-twitter"></i></a>
				<a href="https://github.com/GrgeoireGobert" style="color:#333;font-size:1.3em;"><i class="fab fa-github"></i></a>
				<a href="https://www.linkedin.com/in/greg-gobert/" style="color:rgb(40,103,178);font-size:1.3em;"><i class="fab fa-linkedin-in"></i></a>
			</div>
		</div>
		<div class="column is-2"></div>
	</footer>
	
  <script type="text/javascript" src="script.js"></script>
  </body>
</html>