<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>AInimation</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.8.0/css/bulma.min.css">
	<link href="https://fonts.googleapis.com/css?family=Kaushan+Script&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style_article.css">
    <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
  </head>
  <body>
  
  
  <section id="article_hero"  class="hero is-medium is-primary" style="background-image: url(banners/banner_son_full.jpg);">
  <div class="hero-body">
    <div class="columns">
	<div class="column is-2"></div>
	<div class="column is-8">
      <h1 class="title">
        Son
      </h1>
      <h2 class="subtitle">
        Dialogues, musique, bruitages et ambiance
      </h2>
	</div>
	<div class="column is-2"></div>
    </div>
  </div>
</section>
  
  <div id="burger_menu_full">
	<div id="burger_menu_open" class="burger-menu"><i class="fas fa-bars"></i></div>
	<div id="burger_menu_close" class="burger-menu"><i class="fas fa-times"></i></div>
  </div>
  
  <div id="left_menu" class="left_menu">
	<a id="to_home" href="index.html">AI</a>
	  <nav>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="script.html"><i class="far fa-circle"></i><span class="tooltiptext">Script</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	 
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="storyboard.html"><i class="far fa-circle"></i><span class="tooltiptext">Storyboard</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="modelisation.html"><i class="far fa-circle"></i><span class="tooltiptext">Modélisation</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="texturing.html"><i class="far fa-circle"></i><span class="tooltiptext">Texturing</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="rigging.html"><i class="far fa-circle"></i><span class="tooltiptext">Rigging</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="animation.html"><i class="far fa-circle"></i><span class="tooltiptext">Animation</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="rendu.html"><i class="far fa-circle"></i><span class="tooltiptext">Rendu</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  <div class="point"><a href="son.html"><i class="fas fa-circle"></i><span class="tooltiptext">Son</span></a></div>
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  
	  <i class="fas fa-ellipsis-v" style="font-size:0.5em;"></i>
	  </nav>
	 
	<div></div>
	</div>
	
	<div class="columns">
	  <div class="column is-2"></div>
	  <div class="column is-8">
		<section class="section">
			<div class="container">
			  <h1 class="title">Le son, qu'est-ce que c'est ?</h1>
				  <h2 class="subtitle">
					<!-- Rien pour l'instant --></br>
				  </h2>
				  
				<p>
				Une fois les images générées, il ne reste plus qu'à superposer la bande sonore à la vidéo. Cette bande sonore comporte des sons de types variés : les dialogues des personnages, les bruitages, les ambiances sonores, la musique, etc. Tous ces éléments sont très importants et doivent être conçus minutieusement afin de générer un film d'animation immersif. Par exemple, un léger désaccord entre les paroles d'un personnage et le mouvement de ses lèvres peut être très dérangeant pour le spectateur.<br/><br/>
				</p>
				
				<p>
				En ce qui concerne les paroles des personnages, le problème de la langue se pose. En effet, les artistes créent l'animation faciale du personnage de manière à ce que le mouvement de ses lèvres corresponde aux paroles du personnage dans une langue fixée. Il est ensuite nécessaire de réaliser une opération de doublage afin de proposer le film dans différents langues. Cependant, l'animation ne coïncide pas toujours exactement avec les autres langues. L'intelligence artificielle pourrait résoudre ce problème, en générant automatiquement l'animation des lèvres à partir d'un fichier audio. Cela permettrait donc de générer une animation adaptée à une multitude de langues. Cette méthode va être détaillée par la suite. 
				</p>
				  
			</div>
		</section>
		
		
		
		
		
		
		
		
		
		
		
		<section class="section">
			<div class="container">
			  <h1 class="title">Un doublage parfait</h1>
				  <h2 class="subtitle">
					Les mouvements adaptés à chaque langue.</br>
				  </h2>
				  
				<p>
				Des chercheurs des laboratoires de Disney <a href="#ref_1">[1]</a> ont mis au point une méthode basée sur un algorithme d'intelligence artificielle qui, prenant en entrée un fichier audio, génère une animation des lèvres adaptée. Les grandes étapes de la méthode sont les suivantes :
				</p>
				<ol>
					<li>Une personne quelconque enregistre des paroles dans un fichier audio.</li>
					<li>Le fichier audio est analysé et converti en une séquence de phonèmes grâce à des modèles déjà existants.</li>
					<li>Une fenêtre temporelle glissante sélectionne un fragment de cette séquence de phonèmes.</li>
					<li>Ce fragment est passé en entrée d'un réseau de neurones classique.</li>
					<li>En sortie du réseau de neurones se situent un ensemble de paramètres permettant de générer une animation type de lèvres.</li>
					<li>Cette animation type est ensuite adaptée à la morpholgie du personnage à animer.</li>
				</ol>
				
				<figure class="image" style="width:70%;">
						<img src="images/Speech_Animation_model.png" width="100%"></img>
						<p>L'architecture globale de la méthode d'animation de paroles (<a href="https://la.disneyresearch.com/publication/deep-learning-speech-animation/">source</a>)</p>
				</figure>
				
				<p>
				La conversion du fichier audio en une séquence de phonèmes peut se faire avec n'importe quelle solution adaptée, pas forcément une solution basée sur l'intelligence artificielle. Ensuite, l'analyse de cette séquence de phonèmes via une fenêtre temporelle glissante permet de prendre en compte le phénomène de coarticulation (un phonème est prononcé différemment en fonction des phonèmes qui l'entourent, à cause de l'inertie du système vocal).<br/><br/> 
				</p>
				
				<p>
				Le réseau de neurones utilisé est un réseau de neurones <em>fully connected</em> à trois couches cachées. Chaque couche cachée est composée de 3000 neurones avec fonction d'activation <em>tanh</em>. Les couches d'entrée et de sortie sont adaptées au nombre de paramètres (taille de la fenêtre temporelle et nombre de paramètres pour l'animation). L'entrainement du réseau se fait grâce à un jeu de données audio et vidéo d'un acteur prononçant des phrases composées d'une grande diversité de phonèmes. Les animations buccales "cibles" sont générées par une analyse d'images sur les séquences vidéos.<br/><br/> 
				</p>
				  
				<p>
				L'utilisation d'une animation type permet ensuite de l'adapter facilement à tout type de personnage (dans la limite où celui-ci a une morphologie buccale humanoïde). La figure ci-dessous présente plusieurs exemples de cette étape.
				</p>
				
				
				<figure class="image" style="width:60%;">
						<img src="images/Speech_Animation_retargeting.png" width="100%"></img>
						<p>Exemples de reciblage d'animation faciale. (Première colonne) L'animation type. (Colonnes suivantes) L'animation adaptée aux personnages (<a href="https://la.disneyresearch.com/publication/deep-learning-speech-animation/">source</a>)</p>
				</figure>
				
				<p>
				Les résultats sont obtenus très rapidement, pouvant même ouvir des perpective de temps réel. De plus, les animations générées automatiquement semblent vraiment coïncider avec les paroles, et cela quelque soit la langue employée, comme le montre la vidéo ci-dessous. Cette méthode peut potentiellement être utilisée lors de la production de films d'animation adaptés à chaque langue.
				</p>
				  
				<figure class="image" style="width:80%;">
						<iframe width="100%" height="400" src="https://www.youtube.com/embed/lYTTpazRttc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
						<p>Résultats de la méthode d'animation automatique de la parole (<a href="https://la.disneyresearch.com/publication/deep-learning-speech-animation/">source</a>)</p>
				</figure>
				  
				  
				  
			</div>
		</section>
		
		
		
		
		
		
		
		
		<section class="section">
			<div class="container refs">
				<h1 class="title">Références</h1>
				<ul>
					<li>[1] : DisneyResearch -
						<a id="ref_1" href="https://la.disneyresearch.com/publication/deep-learning-speech-animation/">A Deep Learning Approach for Generalized Speech Animation</a>
					</li>
				</ul>
			</div>
		</section>
		
	  </div>
	  <div class="column is-2"></div>
	</div>
	
	<footer class="columns">
		<div class="column is-2"></div>
		<div class="column is-8" id="footer_center">
			<div>© Grégoire GOBERT</div>
			<div>
				<a href="https://twitter.com/gobert_gregoire" style="color:rgb(29,161,242);font-size:1.3em;"><i class="fab fa-twitter"></i></a>
				<a href="https://github.com/GrgeoireGobert" style="color:#333;font-size:1.3em;"><i class="fab fa-github"></i></a>
				<a href="https://www.linkedin.com/in/greg-gobert/" style="color:rgb(40,103,178);font-size:1.3em;"><i class="fab fa-linkedin-in"></i></a>
			</div>
		</div>
		<div class="column is-2"></div>
	</footer>
	
  <script type="text/javascript" src="script.js"></script>
  </body>
</html>